{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install google-api-python-client\n",
    "# %pip install nltk\n",
    "# %pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Comments Fetched: 27305\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "# Set up API credentials\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"****-YTY\"\n",
    "\n",
    "# Initialize the YouTube API client\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=DEVELOPER_KEY\n",
    ")\n",
    "\n",
    "# Function to fetch all comments\n",
    "def fetch_all_comments(video_id):\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,  # Maximum allowed value\n",
    "            pageToken=next_page_token\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Extract comments from the response\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']\n",
    "            comments.append([\n",
    "                comment['publishedAt'],\n",
    "                comment['likeCount'],\n",
    "                comment['textDisplay']\n",
    "            ])\n",
    "\n",
    "        # Check if there's another page\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "        \n",
    "\n",
    "    return comments\n",
    "\n",
    "# Fetch comments for a video\n",
    "video_id = \"dtp6b76pMak\"  \n",
    "all_comments = fetch_all_comments(video_id)\n",
    "print(f\"Total Comments Fetched: {len(all_comments)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_comments, columns=['dated', 'likes', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27305 entries, 0 to 27304\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   dated   27305 non-null  object\n",
      " 1   likes   27305 non-null  int64 \n",
      " 2   text    27305 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 640.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dooterior/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dooterior/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning libraries\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dated</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-27T21:33:28Z</td>\n",
       "      <td>1</td>\n",
       "      <td>You explain things SUPER WELL!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-27T00:41:30Z</td>\n",
       "      <td>1</td>\n",
       "      <td>Essentially you are using 2 computers at once...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-27T00:36:08Z</td>\n",
       "      <td>0</td>\n",
       "      <td>I would describe as just the beginning or ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-27T00:33:23Z</td>\n",
       "      <td>0</td>\n",
       "      <td>yoðŸ˜®, I would need to buy new jeans and a turt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-27T00:30:20Z</td>\n",
       "      <td>0</td>\n",
       "      <td>You are honestly underselling the actual expe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dated  likes  \\\n",
       "0  2024-12-27T21:33:28Z      1   \n",
       "1  2024-12-27T00:41:30Z      1   \n",
       "2  2024-12-27T00:36:08Z      0   \n",
       "3  2024-12-27T00:33:23Z      0   \n",
       "4  2024-12-27T00:30:20Z      0   \n",
       "\n",
       "                                                text  \n",
       "0                 You explain things SUPER WELL!!!!!  \n",
       "1   Essentially you are using 2 computers at once...  \n",
       "2   I would describe as just the beginning or ear...  \n",
       "3   yoðŸ˜®, I would need to buy new jeans and a turt...  \n",
       "4   You are honestly underselling the actual expe...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    html_tag_pattern = re.compile(r'<a href=\".*?\">.*?</a>')  \n",
    "    return html_tag_pattern.sub('', text)\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df['text'] = df['text'].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the date column to datetime format\n",
    "df['dated'] = pd.to_datetime(df['dated'])\n",
    "\n",
    "# change the datetime format\n",
    "df['date'] = df['dated'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dooterior/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dooterior/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You explain things SUPER WELL!!!!!</td>\n",
       "      <td>explain things super well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Essentially you are using 2 computers at once...</td>\n",
       "      <td>essentially using computers work together big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would describe as just the beginning or ear...</td>\n",
       "      <td>would describe beginning early public rnd cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yoðŸ˜®, I would need to buy new jeans and a turt...</td>\n",
       "      <td>yo would need buy new jeans turtleneck sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are honestly underselling the actual expe...</td>\n",
       "      <td>honestly underselling actual experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                 You explain things SUPER WELL!!!!!   \n",
       "1   Essentially you are using 2 computers at once...   \n",
       "2   I would describe as just the beginning or ear...   \n",
       "3   yoðŸ˜®, I would need to buy new jeans and a turt...   \n",
       "4   You are honestly underselling the actual expe...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                          explain things super well  \n",
       "1  essentially using computers work together big ...  \n",
       "2  would describe beginning early public rnd cons...  \n",
       "3        yo would need buy new jeans turtleneck sick  \n",
       "4            honestly underselling actual experience  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Initialize stopwords list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    #fix contracted words\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # Remove mentions, hashtags, URLs\n",
    "    text = re.sub(r'@\\w+|#\\w+|http\\S+', '', text)\n",
    "    \n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text, preserve_line=True)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join tokens back to a single string\n",
    "    clean_text = ' '.join(tokens)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "# Apply the cleaning function to your text column\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# View the cleaned data\n",
    "\n",
    "df[['text', 'cleaned_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dated</th>\n",
       "      <th>likes</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-12-27 21:33:28+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>You explain things SUPER WELL!!!!!</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>explain things super well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-12-27 00:41:30+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Essentially you are using 2 computers at once...</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>essentially using computers work together big ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-12-27 00:36:08+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>I would describe as just the beginning or ear...</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>would describe beginning early public rnd cons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-27 00:33:23+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>yoðŸ˜®, I would need to buy new jeans and a turt...</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>yo would need buy new jeans turtleneck sick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-12-27 00:30:20+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>You are honestly underselling the actual expe...</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>honestly underselling actual experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      dated  likes  \\\n",
       "0 2024-12-27 21:33:28+00:00      1   \n",
       "1 2024-12-27 00:41:30+00:00      1   \n",
       "2 2024-12-27 00:36:08+00:00      0   \n",
       "3 2024-12-27 00:33:23+00:00      0   \n",
       "4 2024-12-27 00:30:20+00:00      0   \n",
       "\n",
       "                                                text        date  \\\n",
       "0                 You explain things SUPER WELL!!!!!  2024-12-27   \n",
       "1   Essentially you are using 2 computers at once...  2024-12-27   \n",
       "2   I would describe as just the beginning or ear...  2024-12-27   \n",
       "3   yoðŸ˜®, I would need to buy new jeans and a turt...  2024-12-27   \n",
       "4   You are honestly underselling the actual expe...  2024-12-27   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0                          explain things super well  \n",
       "1  essentially using computers work together big ...  \n",
       "2  would describe beginning early public rnd cons...  \n",
       "3        yo would need buy new jeans turtleneck sick  \n",
       "4            honestly underselling actual experience  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"api_data\", user=\"postgres\", password=\"1234!\", host=\"localhost\", port=\"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    cur.execute(\n",
    "        \"INSERT INTO vision_pro_reviews (date, review) VALUES (%s, %s)\",\n",
    "        (row['date'], row['cleaned_text'])\n",
    "    )\n",
    "print('successfully loaded')\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_sql_query(\"SELECT * FROM yt_feedback\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crontab -e\n",
    "\n",
    "# 0 0 * * * 0 0 * * * /usr/bin/python3 /path/to/ytpipeline.py\n",
    "\n",
    "#:wq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
